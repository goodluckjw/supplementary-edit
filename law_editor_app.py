
import streamlit as st
import pandas as pd
import re
from collections import defaultdict
import io
import requests
from bs4 import BeautifulSoup

def extract_article(text):
    match = re.search(r"(ì œ\d+ì¡°(?:ì˜\d+)?)", text)
    return match.group(1) if match else ""

def extract_title(text):
    match = re.search(r"ì œ\d+ì¡°(?:ì˜\d+)?\(([^)]+)\)", text)
    return match.group(1) if match else None

def extract_clause_number(text):
    match = re.search(r"([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³])", text)
    circled_number_map = {
        "â‘ ": "1", "â‘¡": "2", "â‘¢": "3", "â‘£": "4", "â‘¤": "5",
        "â‘¥": "6", "â‘¦": "7", "â‘§": "8", "â‘¨": "9", "â‘©": "10",
        "â‘ª": "11", "â‘«": "12", "â‘¬": "13", "â‘­": "14", "â‘®": "15",
        "â‘¯": "16", "â‘°": "17", "â‘±": "18", "â‘²": "19", "â‘³": "20",
    }
    return circled_number_map.get(match.group(1), None) if match else None

def has_final_consonant(korean_word):
    last_char = korean_word[-1]
    return (ord(last_char) - 44032) % 28 != 0

def format_clauses(clauses):
    if len(clauses) == 1:
        return f"ì œ{clauses[0]}í•­"
    elif len(clauses) == 2:
        return f"ì œ{clauses[0]}í•­ ë° ì œ{clauses[1]}í•­"
    else:
        formatted = ", ".join([f"ì œ{clause}í•­" for clause in clauses[:-1]])
        return f"{formatted} ë° ì œ{clauses[-1]}í•­"

def number_to_circled(num):
    if 1 <= num <= 50:
        return chr(0x2460 + num - 1)
    elif 51 <= num <= 100:
        return chr(0x3251 + num - 51)
    else:
        return f"({num})"

def fetch_law_names_from_url(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    law_names = []
    for td in soup.find_all('td', class_='tl'):
        law_name = td.get_text(strip=True)
        if law_name:
            law_names.append(law_name)
    return law_names

def dummy_law_text(law_name):
    return f"{law_name} ì œ1ì¡°(ëª©ì ) â‘  ì´ ë²•ì€ {law_name}ì— ê´€í•œ ì‚¬í•­ì„ ì •í•œë‹¤. â‘¡ ì§€ë°©ë²•ì›ì€ ì´ì— ë”°ë¥¸ë‹¤."

def process_web_laws(url, original_term, replacement_term):
    law_names = fetch_law_names_from_url(url)
    output_lines = []

    for idx, law_name in enumerate(sorted(law_names), 1):
        text = dummy_law_text(law_name)
        if original_term not in text:
            continue
        circled = number_to_circled(idx)
        article = extract_article(text) or "ì œ1ì¡°"
        clause_number = extract_clause_number(text)
        title = extract_title(text)
        clauses = [clause_number] if clause_number else []

        if original_term in text:
            clause_text = ""
            if title and clauses:
                clause_text = f"{article}ì˜ ì œëª© ë° ê°™ì€ ì¡° {format_clauses(clauses)}"
            elif title:
                clause_text = f"{article}ì˜ ì œëª©"
            elif clauses:
                clause_text = f"{article} {format_clauses(clauses)}"
            else:
                clause_text = f"{article}"

            modified = original_term.replace(original_term, replacement_term)
            particle = "ì„" if has_final_consonant(original_term) else "ë¥¼"
            sentence = f'{law_name} {clause_text} ì¤‘ "{original_term}"{particle} "{modified}"ìœ¼ë¡œ í•œë‹¤.'
            output_lines.append(f"{circled} {law_name} ì¼ë¶€ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê°œì •í•œë‹¤.")
            output_lines.append(sentence)
            output_lines.append("")

    return "\n".join(output_lines)

st.set_page_config(page_title="íƒ€ë²•ê°œì • ë„ìš°ë¯¸", layout="centered")
st.title("ğŸ“˜ íƒ€ë²•ê°œì • ë„ìš°ë¯¸")

st.markdown("""
**ìš©ì–´ ê°œì • í›„ ë¶€ì¹™ì˜ 'ë‹¤ë¥¸ ë²•ë¥ ì˜ ê°œì •'ì„ ê°„í¸í•˜ê²Œ í•˜ê¸° ìœ„í•œ ì•±ì…ë‹ˆë‹¤.**

ğŸ“ *ê°œì„ í•  ì‚¬í•­ì´ë‚˜ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì‚¬ë²•ë²•ì œê³¼ ê¹€ì¬ìš°(4778)ë¡œ ì—°ë½ì£¼ì„¸ìš”.*

---

### ğŸ§¾ ì‚¬ìš© ë°©ë²•:
1. **ë²•ë¥  ëª©ë¡ì´ ìˆëŠ” ì›¹í˜ì´ì§€ ì£¼ì†Œ(URL)**ë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤.  
2. **ì°¾ì„ ë‹¨ì–´**ì™€ **ë°”ê¿€ ë‹¨ì–´**ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.  
3. ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , **í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ**í•©ë‹ˆë‹¤.
""")

url = st.text_input("ğŸ”— ë²•ë¥  ëª©ë¡ URL ì…ë ¥", placeholder="ì˜ˆ: https://likms.assembly.go.kr/law/lawsSrchInqy...")
original_term = st.text_input("ğŸ” ì°¾ì„ ë‹¨ì–´ (ì˜ˆ: ì§€ë°©ë²•ì›)", value="ì§€ë°©ë²•ì›")
replacement_term = st.text_input("âœï¸ ë°”ê¿€ ë‹¨ì–´ (ì˜ˆ: ì§€ì—­ë²•ì›)", value="ì§€ì—­ë²•ì›")

if url and original_term and replacement_term:
    result_text = process_web_laws(url, original_term, replacement_term)

    st.download_button(
        label="ğŸ“¥ ê²°ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        data=result_text,
        file_name="ë²•ë¥ _ê°œì •ì•ˆ_ê²°ê³¼.txt",
        mime="text/plain",
        use_container_width=True
    )

    st.text_area("ğŸ“„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°", result_text, height=400)
else:
    st.info("ğŸ‘† URLê³¼ ë‹¨ì–´ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆì‹œê°€ ê¸°ë³¸ìœ¼ë¡œ ë“¤ì–´ê°€ ìˆìŠµë‹ˆë‹¤.")
